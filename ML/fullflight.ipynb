{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da0f0b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/mnt/c/Users/dhyan/OneDrive/Desktop/FullFight/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import subprocess\n",
    "\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491ab04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef43121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video(name):\n",
    "    return \"../uploads/\" + name\n",
    "\n",
    "# data creation\n",
    "def extract_audio(name):\n",
    "    y, sr = librosa.load(get_video(name), sr=None)\n",
    "    frame_length = int(sr * 0.1)  # 100ms frames\n",
    "    hop_length = frame_length\n",
    "\n",
    "    rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]\n",
    "    times = librosa.frames_to_time(range(len(rms)), sr=sr, hop_length=hop_length)\n",
    "\n",
    "    # Plot\n",
    "    plt.plot(times, 20 * np.log10(rms))  # dB scale\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Volume (dB)\")\n",
    "    plt.title(\"Audio Levels Over Time\")\n",
    "    plt.show()\n",
    "    \n",
    "frame_dir = \"frames\"\n",
    "os.makedirs(frame_dir, exist_ok=True)\n",
    "\n",
    "def extract_frames(name):\n",
    "    subprocess.run([\n",
    "        \"ffmpeg\", \"-i\", name,\n",
    "        \"-vf\", \"fps=10\",\n",
    "        f\"{frame_dir}/{os.path.basename(name)}_frame_%04d.png\"\n",
    "    ])\n",
    "\n",
    "def get_frame_brightness(name):\n",
    "    brightness_data = []\n",
    "\n",
    "    for fname in sorted(os.listdir(frame_dir)):\n",
    "        if fname.endswith(\".png\"):\n",
    "            img = cv2.imread(os.path.join(frame_dir, fname))\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            brightness = np.mean(gray)\n",
    "            brightness_data.append(brightness)\n",
    "    \n",
    "    return brightness_data\n",
    "        \n",
    "timestamps = [i * 0.1 for i in range(len(get_frame_brightness(name)))]\n",
    "plt.plot(timestamps, get_frame_brightness(name))\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Brightness\")\n",
    "plt.title(\"Frame Brightness Over Time\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "extract_audio(\"[Kayoanime] Solo Leveling - S02E06.mkv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c0633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dialouge detection and anger detection\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import datetime\n",
    "import csv\n",
    "\n",
    "input_video = \"input.mkv\"\n",
    "output_audio = \"audio.wav\"\n",
    "anger_threshold = 0.3\n",
    "merge_gap = 3\n",
    "csv_filename = \"angry_sections.csv\"\n",
    "\n",
    "# Extract audio: 16kHz mono WAV (required for Whisper)\n",
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-y\", \"-i\", input_video,\n",
    "    \"-vn\",                      # No video\n",
    "    \"-acodec\", \"pcm_s16le\",     # 16-bit PCM audio\n",
    "    \"-ar\", \"16000\",             # 16kHz sampling rate\n",
    "    \"-ac\", \"1\",                 # Mono\n",
    "    output_audio\n",
    "])\n",
    "\n",
    "# Whipser model\n",
    "model = whisper.load_model(\"base\")  # change model size when tuning\n",
    "result = model.transcribe(output_audio)\n",
    "\n",
    "print(\"ðŸ” Loading emotion classifier...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")\n",
    "emotion_model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")\n",
    "labels = ['anger', 'joy', 'optimism', 'sadness']\n",
    "\n",
    "# Angry per segment\n",
    "angry_segments = []\n",
    "\n",
    "for seg in transcription[\"segments\"]:\n",
    "    text = seg[\"text\"]\n",
    "    start = seg[\"start\"]\n",
    "    end = seg[\"end\"]\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "    with torch.no_grad():\n",
    "        logits = emotion_model(**inputs).logits\n",
    "        probs = F.softmax(logits, dim=1)[0]\n",
    "\n",
    "    anger_score = probs[labels.index(\"anger\")].item()\n",
    "\n",
    "    if anger_score > anger_threshold:\n",
    "        angry_segments.append({\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "            \"text\": text.strip(),\n",
    "            \"anger_score\": anger_score\n",
    "        })\n",
    "\n",
    "# Group angry segmenet\n",
    "grouped_angry_sections = []\n",
    "\n",
    "if angry_segments:\n",
    "    current_group = [angry_segments[0]]\n",
    "    for seg in angry_segments[1:]:\n",
    "        prev = current_group[-1]\n",
    "        if seg['start'] - prev['end'] <= merge_gap:\n",
    "            current_group.append(seg)\n",
    "        else:\n",
    "            grouped_angry_sections.append(current_group)\n",
    "            current_group = [seg]\n",
    "    grouped_angry_sections.append(current_group)\n",
    "\n",
    "# Rank groups and print\n",
    "def sec_to_mmss(sec):\n",
    "    return str(datetime.timedelta(seconds=int(sec)))\n",
    "\n",
    "ranked_sections = []\n",
    "\n",
    "for group in grouped_angry_sections:\n",
    "    start = group[0]['start']\n",
    "    end = group[-1]['end']\n",
    "    avg_anger = sum(s['anger_score'] for s in group) / len(group)\n",
    "    ranked_sections.append({\n",
    "        \"start\": start,\n",
    "        \"end\": end,\n",
    "        \"avg_anger\": avg_anger,\n",
    "        \"segments\": group\n",
    "    })\n",
    "\n",
    "# Sort by avg anger desc\n",
    "ranked_sections.sort(key=lambda x: x[\"avg_anger\"], reverse=True)\n",
    "\n",
    "# Print full grouped anger sections\n",
    "print(\"\\nðŸ”¥ Angriest Sections in the Video:\\n\")\n",
    "for i, section in enumerate(ranked_sections[:5]):  # Get top 5 section, hopefully enough?\n",
    "    print(f\"ðŸ”´ Section {i+1}\")\n",
    "    print(f\"[{sec_to_mmss(section['start'])} â†’ {sec_to_mmss(section['end'])}] | Avg Anger Score: {section['avg_anger']:.2f}\\n\")\n",
    "\n",
    "    for seg in section[\"segments\"]:\n",
    "        print(f\"  ðŸ•’ [{sec_to_mmss(seg['start'])} â†’ {sec_to_mmss(seg['end'])}] | Anger: {seg['anger_score']:.2f}\")\n",
    "        print(f\"  ðŸ—£ï¸  {seg['text']}\\n\")\n",
    "\n",
    "    print(\"------------------------------------------------------------\\n\")\n",
    "\n",
    "with open(csv_filename, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\n",
    "        \"Section Number\",\n",
    "        \"Section Start\",\n",
    "        \"Section End\",\n",
    "        \"Section Avg Anger\",\n",
    "        \"Segment Start\",\n",
    "        \"Segment End\",\n",
    "        \"Segment Anger Score\",\n",
    "        \"Segment Text\"\n",
    "    ])\n",
    "\n",
    "    for i, section in enumerate(ranked_sections[:5], start=1):\n",
    "        section_start = sec_to_mmss(section[\"start\"])\n",
    "        section_end = sec_to_mmss(section[\"end\"])\n",
    "        avg_anger = f\"{section['avg_anger']:.2f}\"\n",
    "\n",
    "        for seg in section[\"segments\"]:\n",
    "            seg_start = sec_to_mmss(seg[\"start\"])\n",
    "            seg_end = sec_to_mmss(seg[\"end\"])\n",
    "            seg_anger = f\"{seg['anger_score']:.2f}\"\n",
    "            seg_text = seg[\"text\"].replace('\\n', ' ').strip()\n",
    "            writer.writerow([\n",
    "                i,\n",
    "                section_start,\n",
    "                section_end,\n",
    "                avg_anger,\n",
    "                seg_start,\n",
    "                seg_end,\n",
    "                seg_anger,\n",
    "                seg_text\n",
    "            ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
